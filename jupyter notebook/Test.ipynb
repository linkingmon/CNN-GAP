{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, r'../')\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "from utils.preprocess import pad_sequences\n",
    "from utils.F1 import F1\n",
    "from net.FS import FS\n",
    "from net.FE import FE\n",
    "from net.net2 import CNN_GAP2\n",
    "from dataset.mydataset import myDataset\n",
    "from utils.freeze_model import freeze, unfreeze\n",
    "from utils.f1_loss import f1_loss\n",
    "from utils.wce import wce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 2, 0, 3, 2])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1, 3, 2, 0, 3, 2])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0.],\n",
       "        [0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot \n",
    "b = torch.zeros(a.size()[0],4)\n",
    "b[torch.arange(a.size()[0]),a] = 1\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRED tensor([[0.9440, 0.5546, 0.9885, 0.2473],\n",
      "        [0.0790, 0.7572, 0.9206, 0.7698],\n",
      "        [0.4257, 0.8066, 0.6271, 0.4482],\n",
      "        [0.8774, 0.9506, 0.1028, 0.5658],\n",
      "        [0.3213, 0.8262, 0.6814, 0.6837],\n",
      "        [0.5272, 0.3485, 0.5280, 0.9197],\n",
      "        [0.5998, 0.1928, 0.3436, 0.9958],\n",
      "        [0.3696, 0.6641, 0.0472, 0.4701],\n",
      "        [0.0950, 0.7347, 0.5834, 0.2356],\n",
      "        [0.0021, 0.4682, 0.4577, 0.7574]])\n",
      "TRUE tensor([2, 0, 3, 1, 1, 1, 1, 1, 1, 1])\n",
      "tensor(1.4930)\n",
      "tensor(1.4930)\n"
     ]
    }
   ],
   "source": [
    "pred = torch.rand((10,4))\n",
    "true = torch.tensor([2,0,3,1,1,1,1,1,1,1])\n",
    "print(\"PRED\", pred)\n",
    "print(\"TRUE\", true)\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor([1,1/7,1,1]).float())\n",
    "print(criterion(pred,true))\n",
    "print(wce(pred, true,  n_class=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[ 0.0776,  0.0526, -0.1689,  0.0387],\n",
      "        [-0.2157,  0.0676,  0.0796,  0.0685],\n",
      "        [ 0.0531,  0.0777,  0.0649, -0.1957],\n",
      "        [ 0.0109, -0.0240,  0.0050,  0.0080],\n",
      "        [ 0.0065, -0.0250,  0.0093,  0.0093],\n",
      "        [ 0.0083, -0.0288,  0.0083,  0.0122],\n",
      "        [ 0.0091, -0.0297,  0.0070,  0.0135],\n",
      "        [ 0.0086, -0.0242,  0.0062,  0.0095],\n",
      "        [ 0.0063, -0.0238,  0.0103,  0.0072],\n",
      "        [ 0.0057, -0.0267,  0.0089,  0.0121]])\n"
     ]
    }
   ],
   "source": [
    "pred.requires_grad = True\n",
    "pred.grad.data.zero_()\n",
    "print(pred.grad)\n",
    "loss = wce(pred, true,  n_class=4)\n",
    "pred.retain_grad()\n",
    "loss.backward()\n",
    "print(pred.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor([[ 0.0776,  0.0526, -0.1689,  0.0387],\n",
      "        [-0.2157,  0.0676,  0.0796,  0.0685],\n",
      "        [ 0.0531,  0.0777,  0.0649, -0.1957],\n",
      "        [ 0.0109, -0.0240,  0.0050,  0.0080],\n",
      "        [ 0.0065, -0.0250,  0.0093,  0.0093],\n",
      "        [ 0.0083, -0.0288,  0.0083,  0.0122],\n",
      "        [ 0.0091, -0.0297,  0.0070,  0.0135],\n",
      "        [ 0.0086, -0.0242,  0.0062,  0.0095],\n",
      "        [ 0.0063, -0.0238,  0.0103,  0.0072],\n",
      "        [ 0.0057, -0.0267,  0.0089,  0.0121]])\n"
     ]
    }
   ],
   "source": [
    "pred.requires_grad = True\n",
    "pred.grad.data.zero_()\n",
    "print(pred.grad)\n",
    "loss = criterion(pred, true)\n",
    "pred.retain_grad()\n",
    "loss.backward()\n",
    "print(pred.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
