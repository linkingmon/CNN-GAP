{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import sys\n",
    "sys.path.insert(0, r'C:\\Users\\USER\\Desktop\\CNN_GAP')\n",
    "from utils.preprocess import pad_sequences\n",
    "from utils.F1 import F1\n",
    "from net.FS import FS\n",
    "from net.FE import FE\n",
    "from net.net2 import CNN_GAP2\n",
    "from dataset.mydataset import myDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Xtrain: 8528\n",
      "Shape of Ytrain (8528,)\n"
     ]
    }
   ],
   "source": [
    "Xtrain = None\n",
    "with open('../Xtrain', 'rb') as fp:\n",
    "    Xtrain = pickle.load(fp)\n",
    "\n",
    "Ytrain = np.load('../Ytrain.npy')\n",
    "\n",
    "print('# of Xtrain:', len(Xtrain))\n",
    "print('Shape of Ytrain', Ytrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8244,)\n",
      "(8244,)\n"
     ]
    }
   ],
   "source": [
    "idx = np.where(Ytrain == 3)\n",
    "Xtrain_won = np.delete(Xtrain, idx, axis=0)\n",
    "Ytrain_won = np.delete(Ytrain, idx, axis=0)\n",
    "print(Xtrain_won.shape)\n",
    "print(Ytrain_won.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain_new = []\n",
    "Ytrain_new = []\n",
    "cut_len = 9000\n",
    "thres = 0.65\n",
    "for i in range(len(Xtrain_won)):\n",
    "    cut = len(Xtrain_won[i]) // cut_len\n",
    "    for j in range(1, cut+1):\n",
    "        Xtrain_new.append(Xtrain_won[i][(j-1)*cut_len:j*cut_len])\n",
    "        Ytrain_new.append(Ytrain_won[i])        \n",
    "    if len(Xtrain_won[i]) % cut_len >= int(cut_len*thres):\n",
    "        x_remain = Xtrain_won[i][cut*cut_len:]\n",
    "        remainder = cut_len - len(x_remain)\n",
    "        Xtrain_new.append(np.pad(x_remain, (int(remainder/2), remainder - int(remainder/2)), 'constant', constant_values=0))\n",
    "        Ytrain_new.append(Ytrain_won[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8738, 1, 9000) (8738,)\n"
     ]
    }
   ],
   "source": [
    "train_data = np.array(Xtrain_new).reshape(len(Ytrain_new),1,cut_len)\n",
    "train_label = np.array(Ytrain_new)\n",
    "print(train_data.shape, train_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6116, 1, 9000]) torch.Size([6116]) torch.Size([2622, 1, 9000]) torch.Size([2622])\n"
     ]
    }
   ],
   "source": [
    "train_data, valid_data, train_label, valid_label = train_test_split(train_data, train_label, test_size=0.3, random_state=42)\n",
    "train_data = torch.from_numpy(train_data).float()\n",
    "valid_data = torch.from_numpy(valid_data).float()\n",
    "train_label = torch.from_numpy(train_label).long()\n",
    "valid_label = torch.from_numpy(valid_label).long()\n",
    "print(train_data.shape, train_label.shape, valid_data.shape, valid_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All model will ne save in folder:  model1\n"
     ]
    }
   ],
   "source": [
    "# create folder\n",
    "filename = 'model1'\n",
    "print('All model will ne save in folder: ', filename)\n",
    "try:\n",
    "    os.mkdir(filename)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_log = open(filename + '/training.log', 'w+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(loader, is_train=True):\n",
    "    acc = 0\n",
    "    running_loss = 0.0\n",
    "    f1_score = F1()\n",
    "    for i, data in enumerate(loader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.cuda()\n",
    "        labels = labels.cuda()\n",
    "        # zero the parameter gradients\n",
    "        if is_train:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = sel(enc(inputs))\n",
    "        predict_labels = torch.argmax(outputs, dim=1)\n",
    "        f1_score.update(predict_labels, labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        temp = (predict_labels == labels)\n",
    "        acc += sum(temp).item()\n",
    "        if is_train:\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if is_train:\n",
    "            print('[Epoch: %3d] [acc:%.4f] [loss: %.4f] [%5d/%5d]' % (epoch + 1, acc/(batch_size*(i+1)), running_loss/(batch_size*(i+1)), batch_size*(i+1), train_label.size()[0]), end='\\r')\n",
    "    return acc, running_loss, f1_score.get_score()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:   1] [acc:0.5667] [loss: 0.9538] [  150/ 6116]\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-8d0906f8d1e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0msel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0macc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_f1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrunning_loss\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-76ea5e3c2537>\u001b[0m in \u001b[0;36mrun\u001b[1;34m(loader, is_train)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[1;31m# print statistics\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0mrunning_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[Epoch: %3d] [acc:%.4f] [loss: %.4f] [%5d/%5d]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macc\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_loss\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'\\r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "trainloader = DataLoader(myDataset(train_data, train_label), batch_size=batch_size)\n",
    "validloader = DataLoader(myDataset(valid_data, valid_label, is_train=False), batch_size=batch_size)  # no aug. for valid data\n",
    "\n",
    "class_weight = compute_class_weight('balanced', [0, 1, 2], train_label.numpy())\n",
    "\n",
    "enc = FE(final_len=int(cut_len/8))\n",
    "sel = FS()\n",
    "enc = enc.cuda()\n",
    "sel = sel.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor(class_weight).float()).cuda()\n",
    "params = list(enc.parameters()) + list(sel.parameters())\n",
    "optimizer = torch.optim.Adam(params, lr=1e-3)\n",
    "\n",
    "highest_f1 = 0\n",
    "for epoch in range(130):\n",
    "    # train\n",
    "    enc = enc.train()\n",
    "    if epoch % 3 == 0:\n",
    "        sel = sel.train()\n",
    "    else:\n",
    "        sel = sel.eval()\n",
    "    acc, running_loss, train_f1 = run(trainloader)\n",
    "    train_acc = acc/train_label.size()[0]\n",
    "    train_loss = running_loss/train_label.size()[0]\n",
    "\n",
    "    # validate\n",
    "    enc = enc.eval()\n",
    "    sel = sel.eval()\n",
    "    acc, running_loss, valid_f1 = run(validloader, is_train=False)\n",
    "    valid_acc = acc/valid_label.size()[0]\n",
    "    valid_loss = running_loss/valid_label.size()[0]\n",
    "    print('>>> [Epoch: %3d] [train_acc:%.4f] [train_loss: %.4f] [train_f1:%.4f] [valid_acc:%.4f] [valid_loss: %.4f] [valid_f1:%.4f]\\n'\n",
    "          % (epoch + 1, train_acc, train_loss, train_f1, valid_acc, valid_loss, valid_f1))\n",
    "\n",
    "    # write history to file\n",
    "    # Epoch, train_acc, train_loss, train_f1, valid_acc, valid_loss, valid_f1    \n",
    "    write_log.write('%3d %.6f %.6f %.6f %.6f %.6f %.6f\\n'\n",
    "       % (epoch + 1, train_acc, train_loss, train_f1, valid_acc, valid_loss, valid_f1))\n",
    "\n",
    "    # save model\n",
    "    if highest_f1 < valid_f1:\n",
    "        torch.save(net.state_dict(), filename+'/model_%05d-%.5f-%.5f-%.5f-%.5f.h5' % (epoch+1, train_acc, train_f1, valid_acc, valid_f1))\n",
    "        highest_f1 = valid_f1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
